{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6e6e38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bfd2ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, act, **kwargs):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels,out_channels,**kwargs,bias=True)\n",
    "        self.act = nn.LeakyReLU(0.2, inplace=True) if act else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.conv(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba6ab2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UpConv(nn.Module):\n",
    "    def __init__(self, channels, scale_factor=2):\n",
    "        super().__init__()\n",
    "        self.upconv = nn.Upsample(scale_factor=scale_factor, mode=\"nearest\")\n",
    "        self.conv = nn.Conv2d(channels, channels, 3, 1, 1, bias=True)\n",
    "        self.act = nn.LeakyReLU(0.2, inplace=True)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.act(self.conv(self.upconv(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40172bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseResidualBlock(nn.Module):\n",
    "    def __init__(self, channels, out_channels=32, residual_beta=0.2):\n",
    "        super().__init__()\n",
    "        self.residual_beta = residual_beta\n",
    "        self.blocks = nn.ModuleList()\n",
    "        \n",
    "        for i in range(5):\n",
    "            self.blocks.append(\n",
    "                ConvBlock(\n",
    "                    channels + out_channels*i,\n",
    "                    out_channels if i<=3 else channels,\n",
    "                    kernel_size= 3,\n",
    "                    stride= 1,\n",
    "                    padding= 1,\n",
    "                    act = True if i<=3 else False\n",
    "                )\n",
    "        )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        new_inputs = x\n",
    "        for block in self.blocks:\n",
    "            out = block(new_inputs)\n",
    "            new_inputs = torch.cat([new_inputs, out], dim=1)\n",
    "        return self.residual_beta * out + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f28a77a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RRDBnet(nn.Module):\n",
    "    def __init__(self, channels, residual_beta=0.2):\n",
    "        super().__init__()\n",
    "        self.residual_beta = residual_beta\n",
    "        self.rrdb = nn.Sequential(*[DenseResidualBlock(channels) for _ in range(3)])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.rrdb(x) * self.residual_beta + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6af7f42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, channels=3, out_channels=64, num_blocks=23):\n",
    "        super().__init__()\n",
    "        self.initial = nn.Conv2d(channels,out_channels,kernel_size=3,stride=1,padding=1,bias=True,)\n",
    "        self.residuals = nn.Sequential(*[RRDBnet(out_channels) for _ in range(num_blocks)])\n",
    "        self.conv = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.upconv = nn.Sequential(\n",
    "            UpConv(out_channels), UpConv(out_channels),\n",
    "        )\n",
    "        self.final = nn.Sequential(\n",
    "            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=True),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(out_channels, channels, 3, 1, 1, bias=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        initial = self.initial(x)\n",
    "        x = self.conv(self.residuals(initial)) + initial\n",
    "        x = self.upconv(x)\n",
    "        return self.final(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e70571e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channels=3, features=[64, 64, 128, 128, 256, 256, 512, 512]):\n",
    "        super().__init__()\n",
    "        blocks = []\n",
    "        for idx, feature in enumerate(features):\n",
    "            blocks.append(\n",
    "                ConvBlock(\n",
    "                    channels,\n",
    "                    feature,\n",
    "                    kernel_size=3,\n",
    "                    stride=1 + idx % 2,\n",
    "                    padding=1,\n",
    "                    act=True\n",
    "                )\n",
    "            )\n",
    "            channels = feature\n",
    "\n",
    "        self.blocks = nn.Sequential(*blocks)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((6, 6)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512*6*6, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1024, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.blocks(x)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c1e67ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intialize_weights(models,scale=0.1):\n",
    "    for m in models.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            nn.init.kaiming_normal_(m.weight.data)\n",
    "            m.weight.data *= scale\n",
    "            \n",
    "        elif isinstance(m, nn.Linear):\n",
    "            nn.init.kaiming_normal_(m.weight.data)\n",
    "            m.weight.data *= scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4c2a843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test():\n",
    "#     gen = Generator()\n",
    "#     disc = Discriminator()\n",
    "#     low_res = 24\n",
    "#     x = torch.randn((5, 3, low_res, low_res))\n",
    "#     gen_out = gen(x)\n",
    "#     disc_out = disc(gen_out)\n",
    "\n",
    "#     print(gen_out.shape)\n",
    "#     print(disc_out.shape)\n",
    "\n",
    "# test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c4d3c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import vgg19\n",
    "\n",
    "# phi_5,4 5th conv layer before maxpooling but after activation\n",
    "\n",
    "class VGGloss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.vgg = vgg19(weights=True).features[:36].eval()\n",
    "        self.loss = nn.MSELoss()\n",
    "\n",
    "        for param in self.vgg.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, inputs, target):\n",
    "        vgg_input_features = self.vgg(inputs)\n",
    "        vgg_target_features = self.vgg(target)\n",
    "        return self.loss(vgg_input_features, vgg_target_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04f082b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "LOAD_MODEL = False\n",
    "SAVE_MODEL = True\n",
    "CHECKPOINT_GEN = \"gen.pth.tar\"\n",
    "CHECKPOINT_DISC = \"disc.pth.tar\"\n",
    "LEARNING_RATE = 1e-4\n",
    "NUM_EPOCHS = 10\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 4\n",
    "HIGH_RES = 96\n",
    "LOW_RES = HIGH_RES // 4\n",
    "IMG_CHANNELS = 3\n",
    "LAMBDA_GP = 10\n",
    "\n",
    "highres_transform = A.Compose(\n",
    "    [\n",
    "        A.Normalize(mean=[0.5, 0.5, 0.5], std=[1, 1, 1]),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "lowres_transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(width=LOW_RES, height=LOW_RES, interpolation=Image.BICUBIC),\n",
    "        A.Normalize(mean=[0, 0, 0], std=[1, 1, 1]),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "both_transforms = A.Compose(\n",
    "    [\n",
    "        A.RandomCrop(width=HIGH_RES, height=HIGH_RES),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_transform = A.Compose(\n",
    "    [\n",
    "        A.Normalize(mean=[0, 0, 0], std=[1, 1, 1]),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e900476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyImageFolder(Dataset):\n",
    "    def __init__(self, root_dir):\n",
    "        super(MyImageFolder, self).__init__()\n",
    "        self.data = []\n",
    "        self.root_dir = root_dir\n",
    "        self.class_names = os.listdir(root_dir)\n",
    "\n",
    "        for index, name in enumerate(self.class_names):\n",
    "            files = os.listdir(os.path.join(root_dir, name))\n",
    "            self.data += list(zip(files, [index] * len(files)))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_file, label = self.data[index]\n",
    "        root_and_dir = os.path.join(self.root_dir, self.class_names[label])\n",
    "\n",
    "        image = np.array(Image.open(os.path.join(root_and_dir, img_file)))\n",
    "        image = both_transforms(image=image)[\"image\"]\n",
    "        high_res = highres_transform(image=image)[\"image\"]\n",
    "        low_res = lowres_transform(image=image)[\"image\"]\n",
    "        return low_res, high_res\n",
    "\n",
    "\n",
    "# def test():\n",
    "#     dataset = MyImageFolder(root_dir=\"faces/\")\n",
    "#     loader = DataLoader(dataset, batch_size=1, num_workers=8)\n",
    "\n",
    "#     for low_res, high_res in loader:\n",
    "#         print(low_res.shape)\n",
    "#         print(high_res.shape)\n",
    "\n",
    "# test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64b974f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_penalty(critic, real, fake):\n",
    "    BATCH_SIZE, C, H, W = real.shape\n",
    "    alpha = torch.rand((BATCH_SIZE, 1, 1, 1)).repeat(1, C, H, W)\n",
    "    interpolated_images = real * alpha + fake.detach() * (1 - alpha)\n",
    "    interpolated_images.requires_grad_(True)\n",
    "\n",
    "    # Calculate critic scores\n",
    "    mixed_scores = critic(interpolated_images)\n",
    "\n",
    "    # Take the gradient of the scores with respect to the images\n",
    "    gradient = torch.autograd.grad(\n",
    "        inputs=interpolated_images,\n",
    "        outputs=mixed_scores,\n",
    "        grad_outputs=torch.ones_like(mixed_scores),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "    gradient = gradient.view(gradient.shape[0], -1)\n",
    "    gradient_norm = gradient.norm(2, dim=1)\n",
    "    gradient_penalty = torch.mean((gradient_norm - 1) ** 2)\n",
    "    return gradient_penalty\n",
    "\n",
    "\n",
    "def save_checkpoint(model, optimizer, filename=\"my_checkpoint.pth.tar\"):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    checkpoint = {\n",
    "        \"state_dict\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "    }\n",
    "    torch.save(checkpoint, filename)\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint_file, model, optimizer, lr):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    checkpoint = torch.load(checkpoint_file, map_location=\"cpu\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "\n",
    "    # If we don't do this then it will just have learning rate of old checkpoint\n",
    "    # and it will lead to many hours of debugging \\:\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group[\"lr\"] = lr\n",
    "\n",
    "\n",
    "def plot_examples(low_res_folder, gen):\n",
    "    files = os.listdir(low_res_folder)\n",
    "\n",
    "    gen.eval()\n",
    "    for file in files:\n",
    "        image = Image.open(\"test_images/\" + file)\n",
    "        with torch.no_grad():\n",
    "            upscaled_img = gen(\n",
    "                config.test_transform(image=np.asarray(image))[\"image\"]\n",
    "                .unsqueeze(0)\n",
    "                .to(config.DEVICE)\n",
    "            )\n",
    "        save_image(upscaled_img * 0.5 + 0.5, f\"saved/{file}\")\n",
    "    gen.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94e889ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-16 00:08:47.566911: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "def train_fn(\n",
    "    loader,\n",
    "    disc,\n",
    "    gen,\n",
    "    opt_gen,\n",
    "    opt_disc,\n",
    "    l1,\n",
    "    vgg_loss,\n",
    "    writer,\n",
    "    tb_step\n",
    "):\n",
    "    loop = tqdm(loader, leave=True)\n",
    "\n",
    "    for idx, (low_res, high_res) in enumerate(loop):\n",
    "        fake = gen(low_res)\n",
    "        critic_real = disc(high_res)\n",
    "        critic_fake = disc(fake.detach())\n",
    "        gp = gradient_penalty(disc, high_res, fake)\n",
    "        loss_critic = (\n",
    "            -(torch.mean(critic_real) - torch.mean(critic_fake))\n",
    "            + LAMBDA_GP * gp\n",
    "        )\n",
    "\n",
    "        opt_disc.zero_grad()\n",
    "        loss_critic.backward()\n",
    "        opt_disc.step()\n",
    "\n",
    "        # Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z))\n",
    "       \n",
    "        l1_loss = 1e-2 * l1(fake, high_res)\n",
    "        adversarial_loss = 5e-3 * -torch.mean(disc(fake))\n",
    "        loss_for_vgg = vgg_loss(fake, high_res)\n",
    "        gen_loss = l1_loss + loss_for_vgg + adversarial_loss\n",
    "\n",
    "        opt_gen.zero_grad()\n",
    "        gen_loss.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        writer.add_scalar(\"Critic loss\", loss_critic.item(), global_step=tb_step)\n",
    "        tb_step += 1\n",
    "\n",
    "        if idx % 100 == 0 and idx > 0:\n",
    "            plot_examples(\"test_images/\", gen)\n",
    "\n",
    "        loop.set_postfix(\n",
    "            gp=gp.item(),\n",
    "            critic=loss_critic.item(),\n",
    "            l1=l1_loss.item(),\n",
    "            vgg=loss_for_vgg.item(),\n",
    "            adversarial=adversarial_loss.item(),\n",
    "        )\n",
    "\n",
    "    return tb_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bd3dbe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zok/joker/.joker/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "  0%|                                                    | 0/25 [00:06<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'LAMBDA_GP' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 72\u001b[0m\n\u001b[1;32m     69\u001b[0m     plot_examples(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_images/\u001b[39m\u001b[38;5;124m\"\u001b[39m, gen)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# This will train from scratch\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 38\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     load_checkpoint(\n\u001b[1;32m     30\u001b[0m         CHECKPOINT_DISC,\n\u001b[1;32m     31\u001b[0m         disc,\n\u001b[1;32m     32\u001b[0m         opt_disc,\n\u001b[1;32m     33\u001b[0m         LEARNING_RATE,\n\u001b[1;32m     34\u001b[0m     )\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_EPOCHS):\n\u001b[0;32m---> 38\u001b[0m     tb_step \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopt_gen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopt_disc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43ml1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvgg_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m SAVE_MODEL:\n\u001b[1;32m     51\u001b[0m         save_checkpoint(gen, opt_gen, filename\u001b[38;5;241m=\u001b[39mCHECKPOINT_GEN)\n",
      "Cell \u001b[0;32mIn[14], line 26\u001b[0m, in \u001b[0;36mtrain_fn\u001b[0;34m(loader, disc, gen, opt_gen, opt_disc, l1, vgg_loss, writer, tb_step)\u001b[0m\n\u001b[1;32m     22\u001b[0m critic_fake \u001b[38;5;241m=\u001b[39m disc(fake\u001b[38;5;241m.\u001b[39mdetach())\n\u001b[1;32m     23\u001b[0m gp \u001b[38;5;241m=\u001b[39m gradient_penalty(disc, high_res, fake)\n\u001b[1;32m     24\u001b[0m loss_critic \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;241m-\u001b[39m(torch\u001b[38;5;241m.\u001b[39mmean(critic_real) \u001b[38;5;241m-\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(critic_fake))\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[43mLAMBDA_GP\u001b[49m \u001b[38;5;241m*\u001b[39m gp\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     29\u001b[0m opt_disc\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     30\u001b[0m loss_critic\u001b[38;5;241m.\u001b[39mbackward()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LAMBDA_GP' is not defined"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    dataset = MyImageFolder(root_dir=\"faces/\")\n",
    "    loader = DataLoader(\n",
    "        dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        pin_memory=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "    )\n",
    "    gen = Generator()\n",
    "    disc = Discriminator()\n",
    "    intialize_weights(gen)\n",
    "    opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.9))\n",
    "    opt_disc = optim.Adam(disc.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.9))\n",
    "    writer = SummaryWriter(\"logs\")\n",
    "    tb_step = 0\n",
    "    l1 = nn.L1Loss()\n",
    "    gen.train()\n",
    "    disc.train()\n",
    "    vgg_loss = VGGloss()\n",
    "\n",
    "    if LOAD_MODEL:\n",
    "        load_checkpoint(\n",
    "            CHECKPOINT_GEN,\n",
    "            gen,\n",
    "            opt_gen,\n",
    "            LEARNING_RATE,\n",
    "        )\n",
    "        load_checkpoint(\n",
    "            CHECKPOINT_DISC,\n",
    "            disc,\n",
    "            opt_disc,\n",
    "            LEARNING_RATE,\n",
    "        )\n",
    "\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        tb_step = train_fn(\n",
    "            loader,\n",
    "            disc,\n",
    "            gen,\n",
    "            opt_gen,\n",
    "            opt_disc,\n",
    "            l1,\n",
    "            vgg_loss,\n",
    "            writer,\n",
    "            tb_step,\n",
    "        )\n",
    "\n",
    "        if SAVE_MODEL:\n",
    "            save_checkpoint(gen, opt_gen, filename=CHECKPOINT_GEN)\n",
    "            save_checkpoint(disc, opt_disc, filename=CHECKPOINT_DISC)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try_model = False\n",
    "\n",
    "    if try_model:\n",
    "        # Will just use pretrained weights and run on images\n",
    "        # in test_images/ and save the ones to SR in saved/\n",
    "        gen = Generator()\n",
    "        opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE, betas=(0.0, 0.9))\n",
    "        load_checkpoint(\n",
    "            CHECKPOINT_GEN,\n",
    "            gen,\n",
    "            opt_gen,\n",
    "            LEARNING_RATE,\n",
    "        )\n",
    "        plot_examples(\"test_images/\", gen)\n",
    "    else:\n",
    "        # This will train from scratch\n",
    "        main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a10d11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".joker",
   "language": "python",
   "name": ".joker"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
